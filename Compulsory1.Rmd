---
subtitle: "TMA4268 Statistical Learning V2022"
title: "Compulsory exercise 1: Group 37"
author: "Oskar JÃ¸rgensen, Halvor Linder Henriksen"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",fig.width=4, fig.height=3,fig.align = "center")
```

```{r,eval=TRUE,echo=FALSE}
# install.packages("knitr") #probably already installed
# install.packages("rmarkdown") #probably already installed
# install.packages("ggplot2") #plotting with ggplot
# install.packages("palmerpenguins")
# install.packages("ggfortify") # For model checking
# install.packages("MASS")
# install.packages("class")
# install.packages("pROC")
# install.packages("plotROC")
# install.packages("boot")
library("knitr")
library("rmarkdown")
library("palmerpenguins")
```

<!--  Etc (load all packages needed). -->


# Problem 1

For this problem you will need to include some LaTex code. Please install latex on your computer and then consult Compulsor1.Rmd for hints how to write formulas in LaTex.

$E[(y_0 - \hat{f}(x_0))^2]$
$=E[y_0^2 -2y_0 \hat{f}(x_0) + \hat{f}(x_0)^2]$
$=E[y_0^2] -2E[y_0 \hat{f}(x_0)] + E[\hat{f}(x_0)^2]$
$=E[y_0]^2 + Var[y_0] -2E[y_0 \hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)]$
$=E[f(x_0) + \epsilon]^2 + Var[f(x_0) + \epsilon] -2E[(f(x_0) + \epsilon) \hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)]$
It is assumed that $\epsilon$ is independent of $x$, and that $E[\epsilon]=0$.
$=E[f(x_0) + \epsilon]^2 + Var[f(x_0) + \epsilon] -2E[\epsilon \hat{f}(x_0)] - 2E[f(x_0) \hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)]$
$=E[f(x_0)]^2 + Var[f(x_0)] + Var[\epsilon] -2E[\epsilon \hat{f}(x_0)] - 2E[f(x_0) \hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)]$
$=E[f(x_0)]^2 - 2E[f(x_0) \hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)] + Var[\epsilon]$
$=f(x_0)^2 - 2f(x_0) E[\hat{f}(x_0)] + E[\hat{f}(x_0)]^2 + Var[\hat{f}(x_0)] + Var[\epsilon]$
$=(f(x_0) -E[\hat{f}(x_0)])^2 + Var[\hat{f}(x_0)] + Var[\epsilon]$
Where 
  $Var[\epsilon]$ is the irreducible error,
  $Var[\hat{f}(x_0)]$ is the variance of the prediction, and 
  $(f(x_0) -E[\hat{f}(x_0)])^2$





## a)

## b)

## c)

## d)

## e)

 

# Problem 2

Here is a code chunk:

```{r, eval=TRUE}
library(palmerpenguins) # Contains the data set "penguins".
data(penguins)
head(penguins)
```


## a)

## b) 
 
## c)


# Problem 3

# Problem 4